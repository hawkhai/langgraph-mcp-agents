#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§æ¨¡å‹è°ƒç”¨ç›‘æ§å’Œæ—¥å¿—è®°å½•æ¨¡å—
è®°å½•æ‰€æœ‰æ¨¡å‹è°ƒç”¨çš„è¾“å…¥å‚æ•°ã€è¾“å‡ºç»“æœã€å·¥å…·è°ƒç”¨ç­‰è¯¦ç»†ä¿¡æ¯
"""

import json
import logging
import os
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Callable
import threading
from dataclasses import dataclass, asdict
from langchain_core.messages import BaseMessage
from langchain_core.messages.ai import AIMessageChunk
from langchain_core.messages.tool import ToolMessage


@dataclass
class ModelCallRecord:
    """æ¨¡å‹è°ƒç”¨è®°å½•æ•°æ®ç»“æ„"""
    timestamp: str
    session_id: str
    thread_id: str
    model_name: str
    model_provider: str
    input_messages: List[Dict]
    input_tokens: Optional[int]
    output_content: str
    output_tokens: Optional[int]
    tool_calls: List[Dict]
    tool_responses: List[Dict]
    processing_time: float
    error: Optional[str]
    metadata: Dict[str, Any]


class ModelLogger:
    """å¤§æ¨¡å‹è°ƒç”¨æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
        log_file = self.log_dir / f"model_calls_{datetime.now().strftime('%Y%m%d')}.jsonl"
        
        # é…ç½®JSON Linesæ ¼å¼çš„æ—¥å¿—è®°å½•å™¨
        self.logger = logging.getLogger('model_calls')
        self.logger.setLevel(logging.INFO)
        
        # ç§»é™¤ç°æœ‰çš„å¤„ç†å™¨ï¼Œé¿å…é‡å¤
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # æ–‡ä»¶å¤„ç†å™¨ - JSON Linesæ ¼å¼
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(logging.Formatter('%(message)s'))
        self.logger.addHandler(file_handler)
        
        # å¯é€‰ï¼šæ§åˆ¶å°å¤„ç†å™¨ç”¨äºè°ƒè¯•
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.DEBUG)
        console_handler.setFormatter(
            logging.Formatter('[%(asctime)s] %(levelname)s: %(message)s')
        )
        self.logger.addHandler(console_handler)
        
        # çº¿ç¨‹é”ï¼Œç¡®ä¿æ—¥å¿—å†™å…¥çš„çº¿ç¨‹å®‰å…¨
        self._lock = threading.Lock()
        
        print(f"ğŸ“Š å¤§æ¨¡å‹è°ƒç”¨æ—¥å¿—è®°å½•å™¨å·²å¯åŠ¨ï¼Œæ—¥å¿—æ–‡ä»¶: {log_file}")
    
    def log_model_call(self, record: ModelCallRecord):
        """è®°å½•æ¨¡å‹è°ƒç”¨"""
        with self._lock:
            try:
                # è½¬æ¢ä¸ºå­—å…¸å¹¶åºåˆ—åŒ–ä¸ºJSON
                record_dict = asdict(record)
                json_str = json.dumps(record_dict, ensure_ascii=False, separators=(',', ':'))
                self.logger.info(json_str)
                
                # åœ¨æ§åˆ¶å°æ˜¾ç¤ºç®€è¦ä¿¡æ¯
                print(f"ğŸ“ [{record.timestamp}] {record.model_provider}/{record.model_name} "
                      f"| è¾“å…¥:{record.input_tokens or '?'}t | è¾“å‡º:{record.output_tokens or '?'}t "
                      f"| è€—æ—¶:{record.processing_time:.2f}s "
                      f"| å·¥å…·:{len(record.tool_calls)}")
                
            except Exception as e:
                print(f"âŒ æ—¥å¿—è®°å½•å¤±è´¥: {e}")
    
    def create_streaming_wrapper(self, 
                                session_id: str,
                                thread_id: str,
                                model_name: str,
                                model_provider: str,
                                input_messages: List[Dict],
                                original_callback: Optional[Callable] = None):
        """
        åˆ›å»ºæµå¼è°ƒç”¨åŒ…è£…å™¨ï¼Œç›‘æ§æ•´ä¸ªæµå¼è¿‡ç¨‹
        
        Returns:
            wrapped_callback: åŒ…è£…åçš„å›è°ƒå‡½æ•°
            get_final_record: è·å–æœ€ç»ˆè®°å½•çš„å‡½æ•°
        """
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        timestamp = datetime.now().isoformat()
        
        # ç´¯ç§¯æ•°æ®
        accumulated_content = []
        tool_calls = []
        tool_responses = []
        error_info = None
        metadata = {}
        
        def wrapped_callback(chunk_data: Dict[str, Any]):
            """åŒ…è£…çš„æµå¼å›è°ƒå‡½æ•°"""
            nonlocal accumulated_content, tool_calls, tool_responses, error_info, metadata
            
            try:
                node = chunk_data.get("node", "")
                content = chunk_data.get("content", "")
                
                # è®°å½•èŠ‚ç‚¹ä¿¡æ¯
                if "metadata" in chunk_data:
                    metadata.update(chunk_data["metadata"])
                
                # å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
                if hasattr(content, 'content'):
                    # AIæ¶ˆæ¯å†…å®¹
                    if isinstance(content.content, str):
                        accumulated_content.append(content.content)
                    elif isinstance(content.content, list):
                        for item in content.content:
                            if isinstance(item, dict) and "text" in item:
                                accumulated_content.append(item["text"])
                
                # å¤„ç†å·¥å…·è°ƒç”¨
                if hasattr(content, 'tool_calls') and content.tool_calls:
                    for tool_call in content.tool_calls:
                        tool_calls.append({
                            "id": getattr(tool_call, 'id', ''),
                            "name": getattr(tool_call, 'name', ''),
                            "args": getattr(tool_call, 'args', {}),
                            "timestamp": datetime.now().isoformat()
                        })
                
                # å¤„ç†å·¥å…·å“åº”
                if isinstance(content, ToolMessage):
                    tool_responses.append({
                        "tool_call_id": getattr(content, 'tool_call_id', ''),
                        "content": getattr(content, 'content', ''),
                        "name": getattr(content, 'name', ''),
                        "timestamp": datetime.now().isoformat()
                    })
                
                # è°ƒç”¨åŸå§‹å›è°ƒ
                if original_callback:
                    return original_callback(chunk_data)
                    
            except Exception as e:
                error_info = str(e)
                print(f"âš ï¸ æµå¼ç›‘æ§å›è°ƒé”™è¯¯: {e}")
        
        def get_final_record() -> ModelCallRecord:
            """è·å–æœ€ç»ˆçš„è°ƒç”¨è®°å½•"""
            end_time = time.time()
            processing_time = end_time - start_time
            
            # è®¡ç®—tokenæ•°é‡ï¼ˆä¼°ç®—ï¼‰
            final_content = "".join(accumulated_content)
            estimated_output_tokens = len(final_content) // 4 if final_content else 0
            estimated_input_tokens = sum(len(str(msg)) for msg in input_messages) // 4
            
            return ModelCallRecord(
                timestamp=timestamp,
                session_id=session_id,
                thread_id=thread_id,
                model_name=model_name,
                model_provider=model_provider,
                input_messages=input_messages,
                input_tokens=estimated_input_tokens,
                output_content=final_content,
                output_tokens=estimated_output_tokens,
                tool_calls=tool_calls,
                tool_responses=tool_responses,
                processing_time=processing_time,
                error=error_info,
                metadata=metadata
            )
        
        return wrapped_callback, get_final_record


class ModelCallTracker:
    """æ¨¡å‹è°ƒç”¨è·Ÿè¸ªå™¨ï¼Œæä¾›ç»Ÿè®¡ä¿¡æ¯"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
    
    def get_today_stats(self) -> Dict[str, Any]:
        """è·å–ä»Šæ—¥è°ƒç”¨ç»Ÿè®¡"""
        today = datetime.now().strftime('%Y%m%d')
        log_file = self.log_dir / f"model_calls_{today}.jsonl"
        
        if not log_file.exists():
            return {"total_calls": 0, "total_tokens": 0, "total_time": 0}
        
        stats = {
            "total_calls": 0,
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "total_time": 0,
            "models": {},
            "tools_used": set(),
            "errors": 0
        }
        
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        record = json.loads(line)
                        stats["total_calls"] += 1
                        stats["total_input_tokens"] += record.get("input_tokens", 0) or 0
                        stats["total_output_tokens"] += record.get("output_tokens", 0) or 0
                        stats["total_time"] += record.get("processing_time", 0)
                        
                        # æŒ‰æ¨¡å‹ç»Ÿè®¡
                        model_key = f"{record.get('model_provider', 'unknown')}/{record.get('model_name', 'unknown')}"
                        if model_key not in stats["models"]:
                            stats["models"][model_key] = 0
                        stats["models"][model_key] += 1
                        
                        # å·¥å…·ä½¿ç”¨ç»Ÿè®¡
                        for tool_call in record.get("tool_calls", []):
                            stats["tools_used"].add(tool_call.get("name", "unknown"))
                        
                        # é”™è¯¯ç»Ÿè®¡
                        if record.get("error"):
                            stats["errors"] += 1
            
            stats["tools_used"] = list(stats["tools_used"])
            stats["total_tokens"] = stats["total_input_tokens"] + stats["total_output_tokens"]
            
        except Exception as e:
            print(f"âŒ ç»Ÿè®¡æ•°æ®è¯»å–å¤±è´¥: {e}")
        
        return stats
    
    def get_stats_summary(self) -> str:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        stats = self.get_today_stats()
        
        summary = f"""
ğŸ“Š ä»Šæ—¥æ¨¡å‹è°ƒç”¨ç»Ÿè®¡
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”¢ æ€»è°ƒç”¨æ¬¡æ•°: {stats['total_calls']}
ğŸ“ æ€»è¾“å…¥Token: {stats['total_input_tokens']:,}
ğŸ“‹ æ€»è¾“å‡ºToken: {stats['total_output_tokens']:,}
ğŸ¯ æ€»Tokenæ•°: {stats['total_tokens']:,}
â±ï¸ æ€»è€—æ—¶: {stats['total_time']:.2f}ç§’
âš ï¸ é”™è¯¯æ¬¡æ•°: {stats['errors']}

ğŸ¤– ä½¿ç”¨çš„æ¨¡å‹:
{chr(10).join(f"  â€¢ {model}: {count}æ¬¡" for model, count in stats['models'].items())}

ğŸ› ï¸ ä½¿ç”¨çš„å·¥å…·:
{chr(10).join(f"  â€¢ {tool}" for tool in stats['tools_used'])}
"""
        return summary


# å…¨å±€æ—¥å¿—è®°å½•å™¨å®ä¾‹
_global_logger: Optional[ModelLogger] = None


def get_model_logger() -> ModelLogger:
    """è·å–å…¨å±€æ¨¡å‹æ—¥å¿—è®°å½•å™¨"""
    global _global_logger
    if _global_logger is None:
        _global_logger = ModelLogger()
    return _global_logger


def init_model_logging(log_dir: str = "logs"):
    """åˆå§‹åŒ–æ¨¡å‹æ—¥å¿—è®°å½•"""
    global _global_logger
    _global_logger = ModelLogger(log_dir)
    return _global_logger


# ä¾¿æ·å‡½æ•°
def log_model_call(**kwargs):
    """è®°å½•æ¨¡å‹è°ƒç”¨çš„ä¾¿æ·å‡½æ•°"""
    logger = get_model_logger()
    record = ModelCallRecord(**kwargs)
    logger.log_model_call(record)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logger = ModelLogger()
    tracker = ModelCallTracker()
    
    # æ¨¡æ‹Ÿä¸€æ¬¡è°ƒç”¨è®°å½•
    test_record = ModelCallRecord(
        timestamp=datetime.now().isoformat(),
        session_id="test_session",
        thread_id="test_thread",
        model_name="gpt-4o",
        model_provider="openai",
        input_messages=[{"role": "user", "content": "æµ‹è¯•æ¶ˆæ¯"}],
        input_tokens=10,
        output_content="æµ‹è¯•å›å¤",
        output_tokens=5,
        tool_calls=[],
        tool_responses=[],
        processing_time=1.5,
        error=None,
        metadata={}
    )
    
    logger.log_model_call(test_record)
    print(tracker.get_stats_summary())

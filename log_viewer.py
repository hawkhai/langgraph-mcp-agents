#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹è°ƒç”¨æ—¥å¿—æŸ¥çœ‹å·¥å…·
ç‹¬ç«‹çš„æ—¥å¿—æŸ¥çœ‹å’Œåˆ†æå·¥å…·
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
import argparse


class LogViewer:
    """æ—¥å¿—æŸ¥çœ‹å™¨"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
    
    def list_log_files(self) -> List[Path]:
        """åˆ—å‡ºæ‰€æœ‰æ—¥å¿—æ–‡ä»¶"""
        if not self.log_dir.exists():
            return []
        return sorted(self.log_dir.glob("model_calls_*.jsonl"))
    
    def read_log_file(self, log_file: Path) -> List[Dict[str, Any]]:
        """è¯»å–æ—¥å¿—æ–‡ä»¶"""
        records = []
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if line.strip():
                        try:
                            record = json.loads(line)
                            records.append(record)
                        except json.JSONDecodeError as e:
                            print(f"âš ï¸ ç¬¬{line_num}è¡ŒJSONè§£æé”™è¯¯: {e}")
        except Exception as e:
            print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
        return records
    
    def show_summary(self, date: str = None):
        """æ˜¾ç¤ºæ—¥å¿—æ‘˜è¦"""
        if date:
            log_files = [self.log_dir / f"model_calls_{date}.jsonl"]
        else:
            log_files = self.list_log_files()
        
        print("ğŸ“Š æ¨¡å‹è°ƒç”¨æ—¥å¿—æ‘˜è¦")
        print("=" * 50)
        
        total_calls = 0
        total_input_tokens = 0
        total_output_tokens = 0
        total_time = 0
        models_used = {}
        tools_used = set()
        errors = 0
        
        for log_file in log_files:
            if not log_file.exists():
                continue
                
            print(f"\nğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file.name}")
            records = self.read_log_file(log_file)
            
            file_calls = len(records)
            file_input_tokens = sum(r.get('input_tokens', 0) or 0 for r in records)
            file_output_tokens = sum(r.get('output_tokens', 0) or 0 for r in records)
            file_time = sum(r.get('processing_time', 0) for r in records)
            file_errors = sum(1 for r in records if r.get('error'))
            
            print(f"  â€¢ è°ƒç”¨æ¬¡æ•°: {file_calls}")
            print(f"  â€¢ è¾“å…¥Token: {file_input_tokens:,}")
            print(f"  â€¢ è¾“å‡ºToken: {file_output_tokens:,}")
            print(f"  â€¢ æ€»è€—æ—¶: {file_time:.2f}ç§’")
            print(f"  â€¢ é”™è¯¯æ¬¡æ•°: {file_errors}")
            
            total_calls += file_calls
            total_input_tokens += file_input_tokens
            total_output_tokens += file_output_tokens
            total_time += file_time
            errors += file_errors
            
            for record in records:
                model_key = f"{record.get('model_provider', 'unknown')}/{record.get('model_name', 'unknown')}"
                models_used[model_key] = models_used.get(model_key, 0) + 1
                
                for tool_call in record.get('tool_calls', []):
                    tools_used.add(tool_call.get('name', 'unknown'))
        
        print(f"\nğŸ“ˆ æ€»è®¡ç»Ÿè®¡:")
        print(f"  â€¢ æ€»è°ƒç”¨æ¬¡æ•°: {total_calls}")
        print(f"  â€¢ æ€»è¾“å…¥Token: {total_input_tokens:,}")
        print(f"  â€¢ æ€»è¾“å‡ºToken: {total_output_tokens:,}")
        print(f"  â€¢ æ€»Tokenæ•°: {(total_input_tokens + total_output_tokens):,}")
        print(f"  â€¢ æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"  â€¢ å¹³å‡è€—æ—¶: {(total_time/total_calls if total_calls > 0 else 0):.2f}ç§’")
        print(f"  â€¢ é”™è¯¯æ¬¡æ•°: {errors}")
        
        if models_used:
            print(f"\nğŸ¤– ä½¿ç”¨çš„æ¨¡å‹:")
            for model, count in sorted(models_used.items(), key=lambda x: x[1], reverse=True):
                print(f"  â€¢ {model}: {count}æ¬¡")
        
        if tools_used:
            print(f"\nğŸ› ï¸ ä½¿ç”¨çš„å·¥å…·:")
            for tool in sorted(tools_used):
                print(f"  â€¢ {tool}")
    
    def show_detailed_log(self, date: str = None, limit: int = 10):
        """æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—è®°å½•"""
        if date:
            log_files = [self.log_dir / f"model_calls_{date}.jsonl"]
        else:
            log_files = self.list_log_files()
        
        print("ğŸ“‹ è¯¦ç»†æ—¥å¿—è®°å½•")
        print("=" * 80)
        
        count = 0
        for log_file in log_files:
            if not log_file.exists():
                continue
                
            records = self.read_log_file(log_file)
            for record in reversed(records):  # æœ€æ–°çš„åœ¨å‰
                if count >= limit:
                    break
                
                print(f"\nğŸ• {record.get('timestamp', 'N/A')}")
                print(f"ğŸ”— ä¼šè¯: {record.get('session_id', 'N/A')} | çº¿ç¨‹: {record.get('thread_id', 'N/A')}")
                print(f"ğŸ¤– æ¨¡å‹: {record.get('model_provider', 'N/A')}/{record.get('model_name', 'N/A')}")
                print(f"ğŸ“ è¾“å…¥Token: {record.get('input_tokens', 'N/A')} | è¾“å‡ºToken: {record.get('output_tokens', 'N/A')}")
                print(f"â±ï¸ è€—æ—¶: {record.get('processing_time', 0):.2f}ç§’")
                
                if record.get('tool_calls'):
                    print(f"ğŸ› ï¸ å·¥å…·è°ƒç”¨: {len(record['tool_calls'])}ä¸ª")
                    for tool_call in record['tool_calls']:
                        print(f"   â€¢ {tool_call.get('name', 'unknown')}")
                
                if record.get('error'):
                    print(f"âŒ é”™è¯¯: {record['error']}")
                
                # æ˜¾ç¤ºè¾“å…¥æ¶ˆæ¯æ‘˜è¦
                input_msg = record.get('input_messages', [])
                if input_msg:
                    content = input_msg[0].get('content', '')
                    preview = content[:100] + "..." if len(content) > 100 else content
                    print(f"ğŸ’¬ è¾“å…¥: {preview}")
                
                # æ˜¾ç¤ºè¾“å‡ºæ‘˜è¦
                output = record.get('output_content', '')
                if output:
                    preview = output[:100] + "..." if len(output) > 100 else output
                    print(f"ğŸ’­ è¾“å‡º: {preview}")
                
                print("-" * 80)
                count += 1
    
    def export_csv(self, date: str = None, output_file: str = None):
        """å¯¼å‡ºä¸ºCSVæ ¼å¼"""
        import csv
        
        if date:
            log_files = [self.log_dir / f"model_calls_{date}.jsonl"]
        else:
            log_files = self.list_log_files()
        
        if not output_file:
            output_file = f"model_calls_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        fieldnames = [
            'timestamp', 'session_id', 'thread_id', 'model_provider', 'model_name',
            'input_tokens', 'output_tokens', 'processing_time', 'tool_calls_count',
            'error', 'input_preview', 'output_preview'
        ]
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for log_file in log_files:
                if not log_file.exists():
                    continue
                
                records = self.read_log_file(log_file)
                for record in records:
                    # å‡†å¤‡CSVè¡Œæ•°æ®
                    row = {
                        'timestamp': record.get('timestamp', ''),
                        'session_id': record.get('session_id', ''),
                        'thread_id': record.get('thread_id', ''),
                        'model_provider': record.get('model_provider', ''),
                        'model_name': record.get('model_name', ''),
                        'input_tokens': record.get('input_tokens', 0),
                        'output_tokens': record.get('output_tokens', 0),
                        'processing_time': record.get('processing_time', 0),
                        'tool_calls_count': len(record.get('tool_calls', [])),
                        'error': record.get('error', ''),
                    }
                    
                    # è¾“å…¥é¢„è§ˆ
                    input_msgs = record.get('input_messages', [])
                    if input_msgs:
                        content = input_msgs[0].get('content', '')
                        row['input_preview'] = content[:200]
                    
                    # è¾“å‡ºé¢„è§ˆ
                    output = record.get('output_content', '')
                    row['output_preview'] = output[:200] if output else ''
                    
                    writer.writerow(row)
        
        print(f"âœ… å·²å¯¼å‡ºåˆ°: {output_file}")


def main():
    parser = argparse.ArgumentParser(description="æ¨¡å‹è°ƒç”¨æ—¥å¿—æŸ¥çœ‹å·¥å…·")
    parser.add_argument('--log-dir', default='logs', help='æ—¥å¿—ç›®å½•è·¯å¾„')
    parser.add_argument('--date', help='æŒ‡å®šæ—¥æœŸ (æ ¼å¼: YYYYMMDD)')
    parser.add_argument('--summary', action='store_true', help='æ˜¾ç¤ºæ‘˜è¦ç»Ÿè®¡')
    parser.add_argument('--detailed', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—')
    parser.add_argument('--limit', type=int, default=10, help='è¯¦ç»†æ—¥å¿—æ˜¾ç¤ºæ¡æ•°é™åˆ¶')
    parser.add_argument('--export-csv', action='store_true', help='å¯¼å‡ºä¸ºCSVæ–‡ä»¶')
    parser.add_argument('--output', help='å¯¼å‡ºæ–‡ä»¶å')
    
    args = parser.parse_args()
    
    viewer = LogViewer(args.log_dir)
    
    if args.export_csv:
        viewer.export_csv(args.date, args.output)
    elif args.detailed:
        viewer.show_detailed_log(args.date, args.limit)
    else:
        viewer.show_summary(args.date)


if __name__ == "__main__":
    main()
